#!/usr/bin/env python3
"""
HeartSound Voice Assistant
å¿ƒéŸ³æ™ºé‰´è¯­éŸ³åŠ©æ‰‹ - æ ‘è“æ´¾ç«¯è¯­éŸ³äº¤äº’ï¼ˆè¯­éŸ³å”¤é†’ç‰ˆï¼‰

æµç¨‹: æŒç»­ç›‘å¬ â†’ æ£€æµ‹åˆ°è¯´è¯è‡ªåŠ¨å½•éŸ³ â†’ é™éŸ³è‡ªåŠ¨åœæ­¢ â†’ ASR â†’ å”¤é†’è¯"å°æ™º"æ£€æµ‹ â†’ OpenClaw â†’ TTS â†’ æ’­æ”¾ â†’ ç»§ç»­ç›‘å¬
"""

import os
import sys
import json
import struct
import subprocess
import tempfile
import wave
import time
import requests
from vosk import Model, KaldiRecognizer

# ============================================================
# Configuration
# ============================================================
OPENCLAW_HTTP = "http://127.0.0.1:18789"

# Audio settings
RATE = 16000
RECORD_SECONDS_MAX = 15       # å•æ¬¡å½•éŸ³æœ€é•¿ç§’æ•°
CHUNK_DURATION = 0.3          # æ¯æ¬¡æ£€æµ‹ç‰‡æ®µé•¿åº¦ï¼ˆç§’ï¼‰
CHUNK_BYTES = int(RATE * 2 * CHUNK_DURATION)  # 16-bit mono

# VAD (Voice Activity Detection) settings
SILENCE_THRESHOLD = 500       # éŸ³é‡é˜ˆå€¼ï¼ˆ16-bit èŒƒå›´ 0~32767ï¼‰
SILENCE_TIMEOUT = 1.5         # è¯´å®Œè¯åé™éŸ³å¤šä¹…åœæ­¢å½•éŸ³ï¼ˆç§’ï¼‰
MIN_SPEECH_DURATION = 0.5     # æœ€çŸ­æœ‰æ•ˆè¯­éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œè¿‡çŸ­ä¸¢å¼ƒ

# Wake word (å”¤é†’è¯)
WAKE_WORDS = ["å°æ™º", "å°çŸ¥", "å°å¿—", "å°æ"]  # åŒ…å«åŒéŸ³å®¹é”™

# Local ASR/TTS (å®Œå…¨å…è´¹ç¦»çº¿)
VOSK_MODEL_PATH = os.path.expanduser("~/models/vosk-cn")
ESPEAK_VOICE = "zh"
ESPEAK_SPEED = "165"

# Audio devices (from arecord -l / aplay -l)
INPUT_DEVICE = "plughw:3,0"   # USB microphone
OUTPUT_DEVICE = "plughw:2,0"  # 3.5mm headphone jack

# ============================================================
# Initialize
# ============================================================
vosk_model = None
if os.path.exists(VOSK_MODEL_PATH):
    try:
        vosk_model = Model(VOSK_MODEL_PATH)
    except Exception as e:
        print(f"âŒ Vosk æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
else:
    print(f"âš ï¸ æœªæ‰¾åˆ° Vosk æ¨¡å‹ç›®å½•: {VOSK_MODEL_PATH}")
    print("   å…ˆä¸‹è½½ä¸­æ–‡æ¨¡å‹å¹¶è§£å‹åˆ°è¯¥ç›®å½•å†è¿è¡Œ")


def get_openclaw_token():
    """Read OpenClaw auth token from config"""
    config_path = os.path.expanduser("~/.openclaw/openclaw.json")
    try:
        with open(config_path, "r") as f:
            config = json.load(f)
        return config.get("gateway", {}).get("auth", {}).get("token", "")
    except Exception:
        return ""


def get_amplitude(raw_data):
    """Calculate max amplitude from raw PCM S16_LE data"""
    n_samples = len(raw_data) // 2
    if n_samples == 0:
        return 0
    samples = struct.unpack(f"<{n_samples}h", raw_data[:n_samples * 2])
    return max(abs(s) for s in samples)


def record_audio():
    """Voice-activated recording using arecord + VAD

    æŒç»­ç›‘å¬éº¦å…‹é£ï¼Œæ£€æµ‹åˆ°äººå£°è‡ªåŠ¨å¼€å§‹å½•éŸ³ï¼Œ
    é™éŸ³è¶…è¿‡ SILENCE_TIMEOUT ç§’è‡ªåŠ¨åœæ­¢ã€‚
    æ— éœ€æŒ‰ä»»ä½•é”®ã€‚
    """
    print("ğŸ‘‚ æ­£åœ¨ç›‘å¬... (è¯´è¯å³å¼€å§‹å½•éŸ³)")

    # ç”¨ arecord æŒç»­å½•åˆ¶åŸå§‹ PCM æµåˆ° stdout
    proc = subprocess.Popen(
        [
            "arecord",
            "-D", INPUT_DEVICE,
            "-f", "S16_LE",
            "-r", str(RATE),
            "-c", "1",
            "-t", "raw",        # è¾“å‡ºåŸå§‹ PCM
            "-q",               # å®‰é™æ¨¡å¼
        ],
        stdout=subprocess.PIPE,
        stderr=subprocess.DEVNULL,
    )

    frames = []
    is_recording = False
    silent_time = 0.0
    speech_time = 0.0
    max_chunks = int(RECORD_SECONDS_MAX / CHUNK_DURATION)

    try:
        for _ in range(max_chunks * 10):  # ç›‘å¬é˜¶æ®µå¯ä»¥ç­‰å¾ˆä¹…
            data = proc.stdout.read(CHUNK_BYTES)
            if not data or len(data) < CHUNK_BYTES:
                break

            amplitude = get_amplitude(data)

            if not is_recording:
                # ç­‰å¾…è¯­éŸ³è§¦å‘
                if amplitude > SILENCE_THRESHOLD:
                    is_recording = True
                    speech_time = CHUNK_DURATION
                    silent_time = 0.0
                    frames = [data]
                    print("ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå¼€å§‹å½•éŸ³...")
            else:
                # æ­£åœ¨å½•éŸ³
                frames.append(data)
                speech_time += CHUNK_DURATION

                if amplitude > SILENCE_THRESHOLD:
                    silent_time = 0.0
                else:
                    silent_time += CHUNK_DURATION

                # é™éŸ³è¶…æ—¶ â†’ åœæ­¢
                if silent_time >= SILENCE_TIMEOUT:
                    print(f"ğŸ”‡ é™éŸ³æ£€æµ‹ï¼Œåœæ­¢å½•éŸ³")
                    break

                # è¶…è¿‡æœ€å¤§æ—¶é•¿ â†’ åœæ­¢
                if speech_time >= RECORD_SECONDS_MAX:
                    print(f"â±ï¸ è¾¾åˆ°æœ€å¤§å½•éŸ³æ—¶é•¿")
                    break
    finally:
        proc.terminate()
        proc.wait()

    if not frames or speech_time < MIN_SPEECH_DURATION:
        print("âŒ è¯­éŸ³å¤ªçŸ­ï¼Œå·²å¿½ç•¥")
        return None

    # ä¿å­˜ä¸º WAV æ–‡ä»¶
    tmp = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
    with wave.open(tmp.name, "wb") as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2)  # 16-bit
        wf.setframerate(RATE)
        wf.writeframes(b"".join(frames))

    duration = speech_time
    size_kb = os.path.getsize(tmp.name) / 1024
    print(f"âœ… å½•éŸ³å®Œæˆ ({duration:.1f}ç§’, {size_kb:.0f}KB)")
    return tmp.name


def speech_to_text(audio_path):
    """Offline speech-to-text using Vosk (å…è´¹æœ¬åœ°ç¦»çº¿)"""
    print("ğŸ”„ æœ¬åœ°è¯­éŸ³è¯†åˆ«ä¸­...")

    if vosk_model is None:
        print("âŒ Vosk æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•è¯†åˆ«")
        try:
            os.unlink(audio_path)
        except OSError:
            pass
        return None

    try:
        with wave.open(audio_path, "rb") as wf:
            # å½•éŸ³å‡½æ•°å·²ä¿è¯ 16k/mono/16bitï¼Œè¿™é‡Œåšä¸€æ¬¡ä¿æŠ¤æ€§æ£€æŸ¥
            if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() != RATE:
                print("âŒ éŸ³é¢‘æ ¼å¼ä¸åŒ¹é…ï¼Œéœ€è¦ 16kHz/å•å£°é“/16bit")
                return None

            rec = KaldiRecognizer(vosk_model, RATE)
            while True:
                data = wf.readframes(4000)
                if len(data) == 0:
                    break
                rec.AcceptWaveform(data)

            result = json.loads(rec.FinalResult())
            text = result.get("text", "").strip()

        if text:
            print(f"ğŸ“ è¯†åˆ«ç»“æœ: {text}")
            return text

        print("âŒ æœªè¯†åˆ«åˆ°æ–‡å­—")
        return None
    except Exception as e:
        print(f"âŒ è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
        return None
    finally:
        try:
            os.unlink(audio_path)
        except OSError:
            pass


def check_wake_word(text):
    """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«å”¤é†’è¯ï¼Œè¿”å›å”¤é†’è¯åé¢çš„æŒ‡ä»¤å†…å®¹

    æ”¯æŒä¸¤ç§ç”¨æ³•ï¼š
    1. "å°æ™ºï¼Œä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·" â†’ ç›´æ¥æå–æŒ‡ä»¤ "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·"
    2. "å°æ™º" (åªè¯´å”¤é†’è¯) â†’ è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºå·²å”¤é†’ä½†éœ€è¦ç»§ç»­å¬æŒ‡ä»¤
    """
    for word in WAKE_WORDS:
        pos = text.find(word)
        if pos != -1:
            # æå–å”¤é†’è¯åé¢çš„å†…å®¹
            after = text[pos + len(word):]
            # å»æ‰å¼€å¤´çš„æ ‡ç‚¹å’Œç©ºæ ¼
            after = after.lstrip("ï¼Œ,ã€‚. ã€ï¼š:ï¼!ï¼Ÿ?")
            return after  # å¯èƒ½æ˜¯ç©ºå­—ç¬¦ä¸²ï¼ˆåªè¯´äº†å”¤é†’è¯ï¼‰
    return None  # æ²¡æœ‰æ£€æµ‹åˆ°å”¤é†’è¯


def chat_with_openclaw(message):
    """Send message to OpenClaw and get response"""
    print("ğŸ¤– æ€è€ƒä¸­...")
    token = get_openclaw_token()

    try:
        # Use OpenClaw HTTP API
        headers = {
            "Content-Type": "application/json",
        }
        if token:
            headers["Authorization"] = f"Bearer {token}"

        response = requests.post(
            f"{OPENCLAW_HTTP}/api/agent/message",
            headers=headers,
            json={
                "message": message,
                "sessionId": "main",
            },
            timeout=30,
        )

        if response.status_code == 200:
            data = response.json()
            reply = data.get("reply", data.get("content", data.get("text", "")))
            if reply:
                print(f"ğŸ’¬ å›å¤: {reply}")
                return reply

        # Fallback: use CLI
        print("  HTTP API æœªå“åº”ï¼Œä½¿ç”¨ CLI æ¨¡å¼...")
        result = subprocess.run(
            ["openclaw", "agent", "--message", message, "--session-id", "main"],
            capture_output=True,
            text=True,
            timeout=60,
        )
        reply = result.stdout.strip()
        if reply:
            # Clean up CLI output (remove header lines)
            lines = reply.split("\n")
            content_lines = []
            for line in lines:
                if line.startswith("ğŸ¦") or line.startswith("â”‚") or line.startswith("â—‡"):
                    continue
                content_lines.append(line)
            reply = "\n".join(content_lines).strip()
            if reply:
                print(f"ğŸ’¬ å›å¤: {reply}")
                return reply

        print("âŒ æœªè·å–åˆ°å›å¤")
        return None

    except Exception as e:
        print(f"âŒ å¯¹è¯å¤±è´¥: {e}")
        return None


def text_to_speech(text):
    """Offline text-to-speech using espeak-ng (å…è´¹æœ¬åœ°ç¦»çº¿)"""
    print("ğŸ”Š æœ¬åœ°è¯­éŸ³åˆæˆä¸­...")
    try:
        tmp = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
        tmp.close()

        # å…ˆç”Ÿæˆ wavï¼Œå†æŒ‰æŒ‡å®šè¾“å‡ºè®¾å¤‡æ’­æ”¾
        subprocess.run(
            [
                "espeak-ng",
                "-v", ESPEAK_VOICE,
                "-s", ESPEAK_SPEED,
                "-w", tmp.name,
                text,
            ],
            check=True,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
        )

        subprocess.run(
            ["aplay", "-D", OUTPUT_DEVICE, tmp.name],
            check=True,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
        )

        os.unlink(tmp.name)
        print("âœ… æ’­æ”¾å®Œæˆ")
    except Exception as e:
        print(f"âŒ è¯­éŸ³åˆæˆå¤±è´¥: {e}")
        print(f"ğŸ“¢ (æ–‡å­—è¾“å‡º): {text}")


def main():
    """Main loop - å”¤é†’è¯æ¨¡å¼ï¼Œè¯´"å°æ™º"æ¿€æ´»"""
    print("=" * 50)
    print("  ğŸ«€ å¿ƒéŸ³æ™ºé‰´ - è¯­éŸ³åŠ©æ‰‹")
    print('  è¯´ "å°æ™º" å”¤é†’ï¼ŒCtrl+C é€€å‡º')
    print("=" * 50)

    while True:
        try:
            # 1. è¯­éŸ³å”¤é†’ + å½•éŸ³ï¼ˆè‡ªåŠ¨æ£€æµ‹å¼€å§‹/ç»“æŸï¼‰
            audio_path = record_audio()
            if not audio_path:
                continue

            # 2. ASR
            text = speech_to_text(audio_path)
            if not text:
                continue

            # 3. å”¤é†’è¯æ£€æµ‹
            command = check_wake_word(text)
            if command is None:
                # æ²¡è¯´å”¤é†’è¯ï¼Œå¿½ç•¥
                print(f"ğŸ’¤ æœªæ£€æµ‹åˆ°å”¤é†’è¯ï¼Œå¿½ç•¥")
                continue

            if command == "":
                # åªè¯´äº†"å°æ™º"ï¼Œæç¤ºå¹¶ç»§ç»­å½•éŸ³ç­‰å¾…æŒ‡ä»¤
                print("âœ¨ æˆ‘åœ¨ï¼Œè¯·è¯´...")
                text_to_speech("æˆ‘åœ¨ï¼Œè¯·è¯´")
                time.sleep(0.3)

                # å½•ç¬¬äºŒæ®µï¼šç­‰å¾…å…·ä½“æŒ‡ä»¤
                audio_path2 = record_audio()
                if not audio_path2:
                    continue
                command = speech_to_text(audio_path2)
                if not command:
                    continue

            print(f"ğŸ¯ æŒ‡ä»¤: {command}")

            # 4. Chat
            reply = chat_with_openclaw(command)
            if not reply:
                continue

            # 5. TTS + Play
            text_to_speech(reply)

            # æ’­æ”¾å®Œæ¯•åçŸ­æš‚ç­‰å¾…ï¼Œé¿å… TTS å°¾éŸ³è¢«å½“ä½œæ–°è¾“å…¥
            time.sleep(0.5)

        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
            time.sleep(1)


if __name__ == "__main__":
    main()
